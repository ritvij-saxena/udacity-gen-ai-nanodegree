{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "f35354cd",
      "metadata": {
        "id": "f35354cd"
      },
      "source": [
        "# Lightweight Fine-Tuning Project"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "560fb3ff",
      "metadata": {
        "id": "560fb3ff"
      },
      "source": [
        "TODO: In this cell, describe your choices for each of the following\n",
        "\n",
        "PEFT Technique:\n",
        "I selected LoRA (Low Rank Adaptation) for its efficiency in fine-tuning large language models with fewer parameters. This approach helps reduce computational costs while maintaining performance by introducing low-rank adaptations to the model's attention mechanism, thereby decreasing computational complexity and memory usage.\n",
        "\n",
        "Model:\n",
        "For sentiment analysis, I chose the GPT-2ForSequenceClassification architecture. GPT-2 is renowned for its effectiveness across various NLP tasks, including classification. By using GPT-2ForSequenceClassification, we leverage the pre-trained GPT-2 weights, which capture rich linguistic patterns and contexts, potentially enhancing performance.\n",
        "\n",
        "Evaluation Approach:\n",
        "I evaluate the model both before and after fine-tuning using the Trainer's evaluate() method. This direct comparison ensures the effectiveness of the fine-tuning process. By using the same metrics and procedures on the validation dataset, we can objectively assess the impact of fine-tuning on model performance.\n",
        "\n",
        "Fine-Tuning Dataset:\n",
        "For fine-tuning, we utilize the Rotten Tomatoes, which is well-suited for the sentiment analysis task at hand."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de8d76bb",
      "metadata": {
        "id": "de8d76bb"
      },
      "source": [
        "## Loading and Evaluating a Foundation Model\n",
        "\n",
        "TODO: In the cells below, load your chosen pre-trained Hugging Face model and evaluate its performance prior to fine-tuning. This step includes loading an appropriate tokenizer and dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "XTRJ4gwiDz5B",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XTRJ4gwiDz5B",
        "outputId": "418a0676-5fb9-4a49-9d79-b7d8cade1752"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.20.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.15.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.1.4)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.4)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.5.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.5.0,>=2023.1.0->datasets) (2024.5.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.23.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.2->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.7.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets #for colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "YTwixZlQrmh-",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YTwixZlQrmh-",
        "outputId": "1da063c8-0090-418c-b359-120649d478d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "peft                             0.12.0\n"
          ]
        }
      ],
      "source": [
        "!pip list | grep \"peft\" || pip install peft"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "f551c63a",
      "metadata": {
        "id": "f551c63a"
      },
      "outputs": [],
      "source": [
        "# importing dependencies.\n",
        "\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer, Trainer, TrainingArguments\n",
        "from transformers import DataCollatorWithPadding, Trainer, TrainingArguments\n",
        "from datasets import load_dataset\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "4935cb4d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4935cb4d",
        "outputId": "4bc67d14-7655-4717-9618-93493820f12d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Loading dataset (train and test splits)\n",
        "splits = [\"train\", \"test\"]\n",
        "dataset = {split: load_dataset(\"cornell-movie-review-data/rotten_tomatoes\", split=split) for split in splits}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "908f1f13",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "908f1f13",
        "outputId": "425d28ec-5c4e-492e-aee5-5e127f75fa27"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'train': Dataset({\n",
              "     features: ['text', 'label'],\n",
              "     num_rows: 8530\n",
              " }),\n",
              " 'test': Dataset({\n",
              "     features: ['text', 'label'],\n",
              "     num_rows: 1066\n",
              " })}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "jwtz80JaebGj",
      "metadata": {
        "id": "jwtz80JaebGj"
      },
      "outputs": [],
      "source": [
        "def compute_stats(dataset, subset_name):\n",
        "    \"\"\"\n",
        "    Compute and print statistics for a subset of a HuggingFace dataset.\n",
        "\n",
        "    :param dataset: A Hugging Face dataset object.\n",
        "    :param subset_name: A string with the name of the subset.\n",
        "\n",
        "    :returns: None\n",
        "    \"\"\"\n",
        "    subset = dataset[subset_name]\n",
        "    sentences = subset['text']\n",
        "    labels = subset['label']\n",
        "\n",
        "    # Number of samples in subset\n",
        "    num_samples = subset.num_rows\n",
        "    print(f'Number of samples in {subset_name} subset: {num_samples}')\n",
        "\n",
        "    # Maximum and minimum length of sequences in the subset\n",
        "    sentence_lengths = [len(sentence) for sentence in sentences]\n",
        "    max_length = max(sentence_lengths)\n",
        "    min_length = min(sentence_lengths)\n",
        "    print(f'Max length of sentence in {subset_name} subset: {max_length}')\n",
        "    print(f'Min length of sentence in {subset_name} subset: {min_length}')\n",
        "\n",
        "    # Labels in the subset\n",
        "    unique_labels = set(labels)\n",
        "    print(f'Labels in {subset_name}: {unique_labels}')\n",
        "\n",
        "    # Percentages of each label in the subset\n",
        "    label_counts = {label: labels.count(label) for label in unique_labels}\n",
        "    label_percentages = {label: (count / num_samples) * 100 for label, count in label_counts.items()}\n",
        "\n",
        "    print(f'Percentages for each label in {subset_name} subset:')\n",
        "    for label, percentage in label_percentages.items():\n",
        "        print(f'- Label {label}: {round(percentage, 2)}%')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "fkdJgj0Geq6C",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fkdJgj0Geq6C",
        "outputId": "4476c136-869e-4245-890f-83e249ca200b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of samples in train subset: 8530\n",
            "Max length of sentence in train subset: 267\n",
            "Min length of sentence in train subset: 4\n",
            "Labels in train: {0, 1}\n",
            "Percentages for each label in train subset:\n",
            "- Label 0: 50.0%\n",
            "- Label 1: 50.0%\n"
          ]
        }
      ],
      "source": [
        "compute_stats(dataset, \"train\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "yFesnjUEerOV",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yFesnjUEerOV",
        "outputId": "ea5fedec-9435-45ca-b84e-3bb953218a0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of samples in test subset: 1066\n",
            "Max length of sentence in test subset: 261\n",
            "Min length of sentence in test subset: 14\n",
            "Labels in test: {0, 1}\n",
            "Percentages for each label in test subset:\n",
            "- Label 0: 50.0%\n",
            "- Label 1: 50.0%\n"
          ]
        }
      ],
      "source": [
        "compute_stats(dataset, \"test\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "MnNJZhmi_N70",
      "metadata": {
        "id": "MnNJZhmi_N70"
      },
      "source": [
        "# Load Tokenizer and tokenize the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "f28c4a78",
      "metadata": {
        "id": "f28c4a78",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "# load the tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained('gpt2')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "xDN4JgG5fDNp",
      "metadata": {
        "id": "xDN4JgG5fDNp"
      },
      "outputs": [],
      "source": [
        "tokenizer.pad_token = tokenizer.eos_token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "019b9f55",
      "metadata": {
        "id": "019b9f55"
      },
      "outputs": [],
      "source": [
        "def preprocess(examples): return tokenizer(examples[\"text\"], padding=True, truncation =True)\n",
        "\n",
        "tokenized_dataset = {}\n",
        "for split in splits:\n",
        "    tokenized_dataset[split] = dataset[split].map(preprocess, batched = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "5176b07f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5176b07f",
        "outputId": "bf3cbcec-9889-4f2a-958e-085272206727"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPT2ForSequenceClassification(\n",
              "  (transformer): GPT2Model(\n",
              "    (wte): Embedding(50257, 768)\n",
              "    (wpe): Embedding(1024, 768)\n",
              "    (drop): Dropout(p=0.1, inplace=False)\n",
              "    (h): ModuleList(\n",
              "      (0-11): 12 x GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2SdpaAttention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (score): Linear(in_features=768, out_features=2, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "base_model = AutoModelForSequenceClassification.from_pretrained('gpt2',\n",
        "                                                      num_labels=2,\n",
        "                                                      id2label={0: \"NEGATIVE\", 1: \"POSITIVE\"},\n",
        "                                                      label2id={\"NEGATIVE\": 0, \"POSITIVE\": 1})\n",
        "\n",
        "base_model.config.pad_token_id = tokenizer.pad_token_id\n",
        "\n",
        "for param in base_model.base_model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "base_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "RqAbwttn_pXZ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RqAbwttn_pXZ",
        "outputId": "d2d80fa0-9aa7-4b44-dc7a-e0477f6e7550"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Linear(in_features=768, out_features=2, bias=False)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "base_model.score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "14fd5fdc",
      "metadata": {
        "id": "14fd5fdc"
      },
      "outputs": [],
      "source": [
        "def compute_metrics(eval_prediction):\n",
        "    predictions, labels = eval_prediction\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "    return {\"accuracy\": (predictions == labels).mean()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "3e298c14",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "id": "3e298c14",
        "outputId": "6a77ba85-6f65-42ff-e5e8-294b78dbeaeb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='67' max='67' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [67/67 04:33]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./model_output\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=1,\n",
        "    weight_decay=0.01,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        ")\n",
        "\n",
        "pretrain_trainer = Trainer(\n",
        "    model=base_model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset[\"train\"],\n",
        "    eval_dataset=tokenized_dataset[\"test\"],\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "base_model_evaluation = pretrain_trainer.evaluate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "yQ0sTtZefqa4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yQ0sTtZefqa4",
        "outputId": "758c7962-1e52-49c5-903b-5b8af40fce59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation result before fine-tuning:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eval_loss': 4.876796722412109,\n",
              " 'eval_accuracy': 0.49906191369606,\n",
              " 'eval_runtime': 284.3872,\n",
              " 'eval_samples_per_second': 3.748,\n",
              " 'eval_steps_per_second': 0.236}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "print(\"Evaluation result before fine-tuning:\")\n",
        "base_model_evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4d52a229",
      "metadata": {
        "id": "4d52a229"
      },
      "source": [
        "## Performing Parameter-Efficient Fine-Tuning\n",
        "\n",
        "TODO: In the cells below, create a PEFT model from your loaded model, run a training loop, and save the PEFT model weights."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "JuB3Akdzmjd9",
      "metadata": {
        "id": "JuB3Akdzmjd9"
      },
      "outputs": [],
      "source": [
        "from peft import  get_peft_model, LoraConfig, TaskType"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "894046c0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "894046c0",
        "outputId": "832aa3a5-1bea-4e08-de82-cef997c3d811"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "model = AutoModelForSequenceClassification.from_pretrained('gpt2',\n",
        "                                                      num_labels=2,\n",
        "                                                      id2label={0: \"NEGATIVE\", 1: \"POSITIVE\"},\n",
        "                                                      label2id={\"NEGATIVE\": 0, \"POSITIVE\": 1})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "-w4gJbzpnGx0",
      "metadata": {
        "id": "-w4gJbzpnGx0"
      },
      "outputs": [],
      "source": [
        "model.config.pad_token_id = tokenizer.pad_token_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "tDriJUsInFcK",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tDriJUsInFcK",
        "outputId": "65c0859f-40d0-4f9b-b2d1-030ffff37b03"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable params: 812,544 || all params: 125,253,888 || trainable%: 0.6487\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/peft/tuners/lora/layer.py:1091: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "config = LoraConfig(\n",
        "                    r=8,\n",
        "                    lora_alpha=32,\n",
        "                    target_modules=['c_attn', 'c_proj'],\n",
        "                    lora_dropout=0.1,\n",
        "                    bias=\"none\",\n",
        "                    task_type=TaskType.SEQ_CLS\n",
        "                )\n",
        "\n",
        "peft_model = get_peft_model(model, config)\n",
        "peft_model.print_trainable_parameters()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "oAXkFGWRBIwt",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oAXkFGWRBIwt",
        "outputId": "85dea023-dc6a-489d-903d-94bd69a01751"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the rock is destined to be the 21st century's new \" conan \" and that he's going to make a splash even greater than arnold schwarzenegger , jean-claud van damme or steven segal .\n",
            "1\n"
          ]
        }
      ],
      "source": [
        "# Rename 'label' column to 'labels'\n",
        "tokenized_dataset[\"train\"] = tokenized_dataset[\"train\"].map(lambda e: {'labels': e['label']}, batched=True, remove_columns=['label'])\n",
        "tokenized_dataset[\"test\"] = tokenized_dataset[\"test\"].map(lambda e: {'labels': e['label']}, batched=True, remove_columns=['label'])\n",
        "\n",
        "# Print to verify\n",
        "print(tokenized_dataset[\"train\"][0][\"text\"])\n",
        "print(tokenized_dataset[\"train\"][0][\"labels\"])\n",
        "\n",
        "# Set the format for PyTorch\n",
        "tokenized_dataset[\"train\"].set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
        "tokenized_dataset[\"test\"].set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "ZFMxxbNaoNHq",
      "metadata": {
        "id": "ZFMxxbNaoNHq"
      },
      "outputs": [],
      "source": [
        "trainer_peft = Trainer(\n",
        "model = peft_model,\n",
        "args = TrainingArguments(\n",
        "    output_dir = \"./lora_model_output\",\n",
        "    learning_rate = 2e-5,\n",
        "    logging_strategy = \"steps\",\n",
        "    per_device_train_batch_size = 12,\n",
        "    per_device_eval_batch_size = 12,\n",
        "    num_train_epochs = 1,\n",
        "    weight_decay = 0.01,\n",
        "    evaluation_strategy = \"epoch\",\n",
        "    save_strategy = \"epoch\",\n",
        "    load_best_model_at_end = True\n",
        "),\n",
        "train_dataset = tokenized_dataset[\"train\"],\n",
        "eval_dataset = tokenized_dataset[\"test\"],\n",
        "tokenizer = tokenizer,\n",
        "data_collator =  DataCollatorWithPadding(tokenizer=tokenizer),\n",
        "compute_metrics = compute_metrics,\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "iThfBNqPED4h",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "iThfBNqPED4h",
        "outputId": "da2da702-a074-4d6e-be5e-a430fed314ec"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='711' max='711' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [711/711 1:32:02, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.672400</td>\n",
              "      <td>0.622547</td>\n",
              "      <td>0.699812</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=711, training_loss=0.6619596843478046, metrics={'train_runtime': 5535.2051, 'train_samples_per_second': 1.541, 'train_steps_per_second': 0.128, 'total_flos': 330172861962240.0, 'train_loss': 0.6619596843478046, 'epoch': 1.0})"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "trainer_peft.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "pLjUBTsTxOnh",
      "metadata": {
        "id": "pLjUBTsTxOnh"
      },
      "outputs": [],
      "source": [
        "peft_model.save_pretrained(\"gpt-lora\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "615b12c6",
      "metadata": {
        "id": "615b12c6"
      },
      "source": [
        "## Performing Inference with a PEFT Model\n",
        "\n",
        "TODO: In the cells below, load the saved PEFT model weights and evaluate the performance of the trained PEFT model. Be sure to compare the results to the results from prior to fine-tuning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "UHu-5MQRghov",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UHu-5MQRghov",
        "outputId": "91c30e27-bc04-4558-f686-0be7a091acc9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from peft import AutoPeftModelForSequenceClassification\n",
        "\n",
        "NUM_LABELS = 2\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "lora_model = AutoPeftModelForSequenceClassification.from_pretrained(\"gpt-lora\", num_labels=NUM_LABELS, ignore_mismatched_sizes=True).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "AcPwIsb-gkcR",
      "metadata": {
        "id": "AcPwIsb-gkcR"
      },
      "outputs": [],
      "source": [
        "lora_model.config.pad_token_id = tokenizer.pad_token_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "863ec66e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "863ec66e",
        "outputId": "788608f4-3f8b-4325-b9b6-cbacca01e1b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./data/sentiment_analysis\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=1,\n",
        "    weight_decay=0.01,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        ")\n",
        "\n",
        "finetuned_trainer = Trainer(\n",
        "    model=lora_model,  # The fine-tuned PEFT model.\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset[\"train\"],\n",
        "    eval_dataset=tokenized_dataset[\"test\"],\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "826oHWyTg9mT",
      "metadata": {
        "id": "826oHWyTg9mT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "4d7faa36-934c-4110-e191-83cebbd00a4b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='67' max='67' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [67/67 04:10]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation results for the fine-tuned model:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eval_loss': 0.622546911239624,\n",
              " 'eval_accuracy': 0.699812382739212,\n",
              " 'eval_runtime': 253.769,\n",
              " 'eval_samples_per_second': 4.201,\n",
              " 'eval_steps_per_second': 0.264}"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "# Evaluate the fine-tuned model on the validation set\n",
        "finetuned_results = finetuned_trainer.evaluate()\n",
        "\n",
        "# Print the evaluation results for the fine-tuned model\n",
        "print(\"Evaluation results for the fine-tuned model:\")\n",
        "finetuned_results"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "CRl7428zg56G",
      "metadata": {
        "id": "CRl7428zg56G"
      },
      "source": [
        "# Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "sY3SkBthhVxC",
      "metadata": {
        "id": "sY3SkBthhVxC"
      },
      "source": [
        "The evaluation results highlight significant improvements in the performance of the PEFT (Parameter-Efficient Fine-Tuned) model compared to the base model, demonstrating the effectiveness of the fine-tuning process. Using LoRA (Low Rank Adaptation) for its efficiency in fine-tuning, we aimed to reduce computational costs while maintaining performance by introducing low-rank adaptations to the model's attention mechanism.\n",
        "\n",
        "For sentiment analysis, the GPT-2ForSequenceClassification architecture was chosen due to its renowned effectiveness across various NLP tasks. By leveraging pre-trained GPT-2 weights, we harness rich linguistic patterns and contexts, enhancing the model's performance.\n",
        "\n",
        "Before fine-tuning, the evaluation results indicated an eval_loss of 4.8768, an eval_accuracy of 0.4991, an eval_runtime of 284.3872 seconds, eval_samples_per_second of 3.748, and eval_steps_per_second of 0.236. After fine-tuning on the Rotten Tomatoes dataset, the model showed a substantial reduction in eval_loss to 0.6225 and an increase in eval_accuracy to 0.6998. Additionally, the fine-tuned model demonstrated improved evaluation runtimes (253.769 seconds vs. 284.3872 seconds) with higher samples per second (4.201 vs. 3.748) and steps per second (0.264 vs. 0.236).\n",
        "\n",
        "These improvements underscore the impact of parameter-efficient fine-tuning in optimizing the model for sentiment analysis. The results validate that fine-tuning with LoRA significantly enhances loss reduction and predictive accuracy while being computationally efficient, making it a highly effective approach for fine-tuning large language models like GPT-2ForSequenceClassification."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}